---
trigger: manual
---
ğŸ¯ AMAÃ‡:
Tamamen offline Ã§alÄ±ÅŸan, TÃ¼rkÃ§e anlayan ve Python / HTML kod Ã¼retebilen yerel yapay zekÃ¢ sistemi oluÅŸtur.

ğŸš€ GEREKSÄ°NÄ°MLER:
1ï¸âƒ£ Kodlama dili: Python 3.10+
2ï¸âƒ£ Model: CodeGemma-2B-Q4_K_M (GGUF sÃ¼rÃ¼mÃ¼)
3ï¸âƒ£ TÃ¼rkÃ§e anlama: dbmdz/bert-base-turkish-cased
4ï¸âƒ£ KÃ¼tÃ¼phaneler: transformers, torch, llama-cpp-python
5ï¸âƒ£ Her ÅŸey offline Ã§alÄ±ÅŸacak. Hugging Face modelleri ilk Ã§alÄ±ÅŸmada indirilecek ve `models/` klasÃ¶rÃ¼nde saklanacak.
6ï¸âƒ£ Sistem komut satÄ±rÄ±ndan Ã§alÄ±ÅŸacak ve kullanÄ±cÄ±dan TÃ¼rkÃ§e istek alacak:
   - â€œbana pythonâ€™da basit hesap makinesi kodu yazâ€
   - â€œbasit bir html form yapâ€
   - â€œcss ile buton tasarlaâ€
7ï¸âƒ£ YalnÄ±zca dÃ¼zgÃ¼n formatlÄ± kod dÃ¶ndÃ¼recek. AÃ§Ä±klama veya yorum olmayacak.

ğŸ“¦ DOSYA YAPISI:
YeniAI/
â”‚
â”œâ”€â”€ main.py                # Ana kontrol akÄ±ÅŸÄ±
â”œâ”€â”€ nlu.py                 # TÃ¼rkÃ§e anlama
â”œâ”€â”€ generator.py           # CodeGemma modeliyle kod Ã¼retimi
â”œâ”€â”€ config.py              # Model yollarÄ± ve ayarlar
â”œâ”€â”€ requirements.txt
â””â”€â”€ models/
    â”œâ”€â”€ bert-base-turkish/
    â””â”€â”€ CodeGemma-2B.Q4_K_M.gguf

âš™ï¸ GÃ–REVLER:
1. YukarÄ±daki yapÄ±yÄ± oluÅŸtur.
2. AÅŸaÄŸÄ±daki kodlarÄ± dosyalara yerleÅŸtir:

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“„ requirements.txt
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
transformers
torch
llama-cpp-python
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ config.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_NLU = "models/bert-base-turkish-cased"
MODEL_CODE = "models/CodeGemma-2B.Q4_K_M.gguf"
GPU_LAYERS = 20
MAX_TOKENS = 800
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ nlu.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class IntentDetector:
    def __init__(self, model_path):
        print("ğŸ§  TÃ¼rkÃ§e NLU modeli yÃ¼kleniyor...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        print("âœ… NLU modeli hazÄ±r!")

    def analyze(self, text):
        lower = text.lower()

        # Basit dil tespiti
        if "python" in lower:
            lang = "Python"
        elif "html" in lower:
            lang = "HTML"
        elif "css" in lower:
            lang = "CSS"
        elif "javascript" in lower or "js" in lower:
            lang = "JavaScript"
        else:
            lang = "Python"

        # Niyet belirleme
        if any(x in lower for x in ["kod", "program", "Ã¶rnek", "tasarla", "oluÅŸtur"]):
            intent = "kod_isteÄŸi"
        else:
            intent = "bilgi_sorgusu"

        return intent, lang
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ generator.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from llama_cpp import Llama
from config import MODEL_CODE, GPU_LAYERS, MAX_TOKENS

class CodeGenerator:
    def __init__(self):
        print("ğŸ’» CodeGemma modeli yÃ¼kleniyor...")
        self.llm = Llama(
            model_path=MODEL_CODE,
            n_ctx=4096,
            n_gpu_layers=GPU_LAYERS,
            n_threads=8,
            verbose=False
        )
        print("âœ… CodeGemma yÃ¼klendi!")

    def generate_code(self, prompt, intent, language):
        if intent != "kod_isteÄŸi":
            return "Bu sistem yalnÄ±zca kod Ã¼retimi iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r."

        system_prompt = (
            f"Sen deneyimli bir {language} geliÅŸtiricisisin. "
            f"KullanÄ±cÄ±nÄ±n isteÄŸini yalnÄ±zca dÃ¼zgÃ¼n biÃ§imlendirilmiÅŸ {language} kodu olarak yanÄ±tla. "
            f"AÃ§Ä±klama veya yorum ekleme."
        )

        final_prompt = f"{system_prompt}\n\nKullanÄ±cÄ± isteÄŸi: {prompt}\n\n{language} kodu:\n"

        output = self.llm(
            prompt=final_prompt,
            max_tokens=MAX_TOKENS,
            temperature=0.6,
            stop=["KullanÄ±cÄ±:"]
        )

        return output["choices"][0]["text"].strip()
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“„ main.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from nlu import IntentDetector
from generator import CodeGenerator
from config import MODEL_NLU

nlu = IntentDetector(MODEL_NLU)
coder = CodeGenerator()

print("\nğŸš€ CodeAI baÅŸlatÄ±ldÄ± (Offline). Kod Ã¼retmek iÃ§in komut yazÄ±n ('exit' ile Ã§Ä±k):\n")

while True:
    query = input("ğŸ’¬ Komut: ")
    if query.lower() in ["exit", "Ã§Ä±k", "quit"]:
        print("ğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
        break

    intent, lang = nlu.analyze(query)
    print(f"ğŸ§© Dil: {lang} | Niyet: {intent}")

    code = coder.generate_code(query, intent, lang)
    print("\nğŸ’» Ãœretilen Kod:\n")
    print(code)
    print("\n" + "-"*60 + "\n")
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“¦ MODEL Ä°NDÄ°RME ADIMLARI (otomatik veya el ile):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mkdir models
cd models

# TÃ¼rkÃ§e anlama modeli
git clone https://huggingface.co/dbmdz/bert-base-turkish-cased

# CodeGemma modeli (1.1 GB)
wget https://huggingface.co/TheBloke/CodeGemma-2B-GGUF/resolve/main/CodeGemma-2B.Q4_K_M.gguf -O CodeGemma-2B.Q4_K_M.gguf
cd ..

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… TAMAMLANINCA TEST:
python main.py

ğŸ’¬ Ã–rnek sorgular:
- "bana python'da basit hesap makinesi kodu yaz"
- "basit bir html form tasarla"
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€